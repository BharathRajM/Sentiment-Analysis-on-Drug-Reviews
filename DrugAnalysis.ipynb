{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DrugAnalysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqKi_WxibDdF",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Analysis on Drug Reviews\n",
        "\n",
        "\n",
        "\n",
        "## Approach\n",
        "\n",
        "- Explore the dataset\n",
        "- Clean the reviews\n",
        "- Once the reviews are cleaned we start with the bag of words model (tokenization)\n",
        "- Deduce the feature vectors from the bag of words\n",
        "- Create a classifier (here we use a random forest classifier - set of decision trees) to classify the review as positive,neutral or negative\n",
        "- After this let's test it with the test dataset\n",
        "-Store the test results tp a new csv file\n",
        "\n",
        "\n",
        "labels:\n",
        "- positive \"2\"\n",
        "- negative \"1\"\n",
        "- neutral \"0\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFo7KRKbcQWI",
        "colab_type": "text"
      },
      "source": [
        "### Let's start by importing the necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gos_X0-hwsSG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4d2f0333-e55b-4a5a-e972-b8b91cd6624d"
      },
      "source": [
        "import os\n",
        "\n",
        "# to create a bag of words model\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# RandomForestClassifier will be our model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "# To convert words to vectors\n",
        "from KaggleWord2VecUtility import KaggleWord2VecUtility\n",
        "\n",
        "# To read and load the csv files\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# To save and load our model\n",
        "import pickle"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM1TTPG6w_1V",
        "colab_type": "code",
        "outputId": "a80396d2-9240-4254-e775-99d126d8b93e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#load the dataset\n",
        "df2 = pd.read_csv(\"drugsComTrain.csv\",delimiter=\",\")\n",
        "\n",
        "#drop columns which are not required\n",
        "#The required columns are only the \"review\" and \"ratingSentiment\"\n",
        "df2 = df2.drop(['Id'],axis=1)\n",
        "df2 = df2.drop(['rating'],axis=1)\n",
        "df2 = df2.drop(['ratingSentimentLabel'],axis=1)\n",
        "\n",
        "#Let's see our dataset\n",
        "df2.head()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>ratingSentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"I've tried a few antidepressants over the yea...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"My son has Crohn's disease and has done very ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"Quick reduction of symptoms\"</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"Contrave combines drugs that were used for al...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"I have been on this birth control for one cyc...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  ratingSentiment\n",
              "0  \"I've tried a few antidepressants over the yea...                2\n",
              "1  \"My son has Crohn's disease and has done very ...                2\n",
              "2                      \"Quick reduction of symptoms\"                2\n",
              "3  \"Contrave combines drugs that were used for al...                2\n",
              "4  \"I have been on this birth control for one cyc...                2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQIXnlnxdBX1",
        "colab_type": "text"
      },
      "source": [
        "### Cleaning the dataset\n",
        "\n",
        "Once the dataset is loaded, we take only the required columns viz. \"review\" and \"ratingSentiment\"\n",
        "\n",
        "We cannot directly send the raw reviews to our classifier, because the classifer will start overfitting on the common words like ('the','and', 'or','this','that' .. etc). To avoid this, we will have to remove these common words from the reviews.\n",
        "We do this by taking the help of our helper class \"[KaggleWord2VecUtility](https://github.com/wendykan/DeepLearningMovies/blob/master/KaggleWord2VecUtility.py)\". This helps us remove the stop words.\n",
        "\n",
        "We store the cleaned reviews and use this to train our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eBtfzknx7Q_",
        "colab_type": "code",
        "outputId": "f808e5b3-9683-44b9-84c4-9f07643396bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "\n",
        "clean_train_reviews=[]\n",
        "print('Cleaning and parsing the training set reviews')\n",
        "for i in range(0, len(df2[\"review\"])):\n",
        "  clean_train_reviews.append(\" \".join(KaggleWord2VecUtility.review_to_wordlist(df2['review'][i],True)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cleaning and parsing the training set reviews\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/KaggleWord2VecUtility.py:22: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 22 of the file /content/KaggleWord2VecUtility.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  review_text = BeautifulSoup(review).get_text()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqQjPdYleT3I",
        "colab_type": "text"
      },
      "source": [
        "### Create a bag of words\n",
        "\n",
        "Bag of words is essentially a big matrix of all the words present where the (frequency of) occurrence of each word is used as a feature for training a classifier\n",
        "\n",
        "These features are stored in the train_data_features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfpWHCUry7TN",
        "colab_type": "code",
        "outputId": "eca66776-c2b5-4e95-8b75-545e7ed7a8be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Create the bag of words\n",
        "print(\"Creating a bag of words \\n\")\n",
        "vectorizer = CountVectorizer(analyzer=\"word\", tokenizer = None,preprocessor = None,stop_words = None, max_features = 5000)\n",
        "train_data_features = vectorizer.fit_transform(clean_train_reviews)\n",
        "train_data_features = train_data_features.toarray()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating a bag of words \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8sBvK0aexL9",
        "colab_type": "text"
      },
      "source": [
        "### Training Random Forest Classifier\n",
        "\n",
        "A random forest classifier is a tree of trees. It tries to narrow down the sentiment(positive,negative,neutral) by passing the review through this tree(here it is a tree of 100 sub trees)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHqaNWWrzv5L",
        "colab_type": "code",
        "outputId": "cb04f067-a4c8-40f9-9cb4-2a66806d4136",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print('Training the random forest')\n",
        "forest = RandomForestClassifier(n_estimators = 100)\n",
        "forest.fit(train_data_features,df2['ratingSentiment'])\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training the random forest\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpQ-56-d9har",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "8a525918-04ef-40ee-fdd7-a6a9a3dcd08a"
      },
      "source": [
        "print(\"Model metrics - \")\n",
        "print('Trained model',forest)\n",
        "print(\"Train Accuracy :: \",accuracy_score(df2['ratingSentiment'], forest.predict(train_data_features)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model metrics - \n",
            "Trained model RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "Train Accuracy ::  0.9995164207697279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPAtIES1fnHD",
        "colab_type": "text"
      },
      "source": [
        "### Saving the trained model\n",
        "\n",
        "Once the training is done, let's save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9zcziCffvm2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save the model to disk\n",
        "filename = 'finalized_model.sav'\n",
        "pickle.dump(forest, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9wK31sxgw2b",
        "colab_type": "text"
      },
      "source": [
        "### Loading the model from disk\n",
        "\n",
        "To load the trained model saved above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JSJYy4bg2di",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load model from disk\n",
        "model = pickle.load(open(filename,'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktGxXZRbgWaO",
        "colab_type": "text"
      },
      "source": [
        "### Testing the classifier\n",
        "\n",
        "We do the same steps we did with the raw training data, i.e clean the reviews and drop unwanted columns.\n",
        "\n",
        "Since, we are testing, we don't need any column other than \"review\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoRrZbVEzxnm",
        "colab_type": "code",
        "outputId": "26e11970-a817-4864-f15c-ca37b9cb911c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Format testing data\n",
        "clean_test_reviews=[]\n",
        "dftest = pd.read_csv('drugsComTest.csv')\n",
        "print('Cleaning and parsing the test data reviews')\n",
        "dftest = dftest.drop(['Id'],axis = 1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cleaning and parsing the test data reviews\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Doeb0UAAhTv_",
        "colab_type": "text"
      },
      "source": [
        "Let's see if we have only the reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0DHCrfShJI7",
        "colab_type": "code",
        "outputId": "e0555b44-9c19-4c65-d210-61a669b13161",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "dftest.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"I've tried a few antidepressants over the yea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"My son has Crohn's disease and has done very ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"Quick reduction of symptoms\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"Contrave combines drugs that were used for al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"I have been on this birth control for one cyc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review\n",
              "0  \"I've tried a few antidepressants over the yea...\n",
              "1  \"My son has Crohn's disease and has done very ...\n",
              "2                      \"Quick reduction of symptoms\"\n",
              "3  \"Contrave combines drugs that were used for al...\n",
              "4  \"I have been on this birth control for one cyc..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2LkKP6F4Q05",
        "colab_type": "text"
      },
      "source": [
        "### Extract the data features of test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlKsHphJGti3",
        "colab_type": "code",
        "outputId": "dd8ee5a9-6a5a-4bf2-b234-ba6c451f0b03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "clean_test_review=[]\n",
        "for i in range(0,len(dftest['review'])):\n",
        "  clean_test_reviews.append(\" \".join(KaggleWord2VecUtility.review_to_wordlist(dftest['review'][i],True)))\n",
        "\n",
        "test_data_features = vectorizer.transform(clean_test_reviews)\n",
        "test_data_features = test_data_features.toarray()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/KaggleWord2VecUtility.py:22: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 22 of the file /content/KaggleWord2VecUtility.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  review_text = BeautifulSoup(review).get_text()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sjELIFT4dfm",
        "colab_type": "text"
      },
      "source": [
        "### Predicting the sentiment\n",
        "\n",
        "We can now use our classifier to predict the sentiment of our test dataset by running the classifier on the test data features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt9J8GSINkCi",
        "colab_type": "code",
        "outputId": "8b69a921-5131-4a2e-ea32-a1c124a76cfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Predicting the sentiment of the test reviews')\n",
        "result = forest.predict(test_data_features)\n",
        "output = pd.DataFrame( data={'review':dftest[\"review\"],'Predictedsentiment':result} )\n",
        "output.to_csv(\"TestBagOfWordsModel.csv\")\n",
        "print(\"Wrote results to file\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting the sentiment of the test reviews\n",
            "Wrote results to file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV6aexvsPbPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
